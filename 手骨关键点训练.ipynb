{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T05:38:07.168081300Z",
     "start_time": "2025-06-07T05:37:50.012848500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  no model scale passed. Assuming scale='n'.\n",
      "Ultralytics 8.3.36  Python-3.8.20 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8192MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0mtask=detect, mode=train, model=E:/ultralytics-main/ultralytics/cfg/models/v8/yolov8.yaml, data=./data/BonesOfHand_keypoint/YOLODataset/dataset.yaml, epochs=200, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=0, project=None, name=train203, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=2025, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train203\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "WARNING  no model scale passed. Assuming scale='n'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv8 summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients\n",
      "\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs\\detect\\train203', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\Administrator\\Desktop\\Chinese\\data\\BonesOfHand_keypoint\\YOLODataset\\labels\\train.cache... 880 images, 0 backgrounds, 0 corrupt: 100%|██████████| 880/880 [00:00<?, ?it/s]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\Administrator\\Desktop\\Chinese\\data\\BonesOfHand_keypoint\\YOLODataset\\labels\\val.cache... 220 images, 0 backgrounds, 0 corrupt: 100%|██████████| 220/220 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train203\\labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function TransformNode.set_children.<locals>.<lambda> at 0x0000015814AD5EE0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\y8work\\lib\\site-packages\\matplotlib\\transforms.py\", line 209, in <lambda>\n",
      "    self, lambda _, pop=child._parents.pop, k=id(self): pop(k))\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1mruns\\detect\\train203\u001B[0m\n",
      "Starting training for 200 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/200      2.25G       4.96      3.286      3.204        210        640:  45%|████▍     | 49/110 [00:10<00:13,  4.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 19\u001B[0m\n\u001B[0;32m     16\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mKMP_DUPLICATE_LIB_OK\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTRUE\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./data/BonesOfHand_keypoint/YOLODataset/dataset.yaml\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m                \u001B[49m\u001B[43mcache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m                \u001B[49m\u001B[43mimgsz\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m640\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m                \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m                \u001B[49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m                \u001B[49m\u001B[43mclose_mosaic\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[43m                \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[43m                \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[43m                \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mSGD\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[43m                \u001B[49m\u001B[43mamp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[43m                \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2025\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     30\u001B[0m \u001B[43m                \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# results = model.train(data=r'./data/BonesOfHand_keypoint/YOLODataset/dataset.yaml' ,\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m#                       epochs=500,imgsz=640, batch=16,verbose=False,pose=25, seed=2024)\u001B[39;00m\n",
      "File \u001B[1;32mE:\\ultralytics-main\\ultralytics\\engine\\model.py:802\u001B[0m, in \u001B[0;36mModel.train\u001B[1;34m(self, trainer, **kwargs)\u001B[0m\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mmodel\n\u001B[0;32m    801\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mhub_session \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession  \u001B[38;5;66;03m# attach optional HUB session\u001B[39;00m\n\u001B[1;32m--> 802\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    803\u001B[0m \u001B[38;5;66;03m# Update model and cfg after training\u001B[39;00m\n\u001B[0;32m    804\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m RANK \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m}:\n",
      "File \u001B[1;32mE:\\ultralytics-main\\ultralytics\\engine\\trainer.py:208\u001B[0m, in \u001B[0;36mBaseTrainer.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    205\u001B[0m         ddp_cleanup(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mstr\u001B[39m(file))\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 208\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mworld_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\ultralytics-main\\ultralytics\\engine\\trainer.py:381\u001B[0m, in \u001B[0;36mBaseTrainer._do_train\u001B[1;34m(self, world_size)\u001B[0m\n\u001B[0;32m    379\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mamp):\n\u001B[0;32m    380\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess_batch(batch)\n\u001B[1;32m--> 381\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_items \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    382\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m RANK \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    383\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m world_size\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\y8work\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\y8work\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mE:\\ultralytics-main\\ultralytics\\nn\\tasks.py:134\u001B[0m, in \u001B[0;36mBaseModel.forward\u001B[1;34m(self, x, *args, **kwargs)\u001B[0m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;124;03mPerform forward pass of the model for either training or inference.\u001B[39;00m\n\u001B[0;32m    122\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;124;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001B[39;00m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mdict\u001B[39m):  \u001B[38;5;66;03m# for cases of training and validating while training.\u001B[39;00m\n\u001B[1;32m--> 134\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mE:\\ultralytics-main\\ultralytics\\nn\\tasks.py:325\u001B[0m, in \u001B[0;36mBaseModel.loss\u001B[1;34m(self, batch, preds)\u001B[0m\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcriterion \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_criterion()\n\u001B[0;32m    324\u001B[0m preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;28;01mif\u001B[39;00m preds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m preds\n\u001B[1;32m--> 325\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\ultralytics-main\\ultralytics\\utils\\loss.py:233\u001B[0m, in \u001B[0;36mv8DetectionLoss.__call__\u001B[1;34m(self, preds, batch)\u001B[0m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;66;03m# Targets\u001B[39;00m\n\u001B[0;32m    232\u001B[0m targets \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_idx\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m), batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcls\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m), batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbboxes\u001B[39m\u001B[38;5;124m\"\u001B[39m]), \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m--> 233\u001B[0m targets \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtargets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_tensor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimgsz\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    234\u001B[0m gt_labels, gt_bboxes \u001B[38;5;241m=\u001B[39m targets\u001B[38;5;241m.\u001B[39msplit((\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m4\u001B[39m), \u001B[38;5;241m2\u001B[39m)  \u001B[38;5;66;03m# cls, xyxy\u001B[39;00m\n\u001B[0;32m    235\u001B[0m mask_gt \u001B[38;5;241m=\u001B[39m gt_bboxes\u001B[38;5;241m.\u001B[39msum(\u001B[38;5;241m2\u001B[39m, keepdim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\u001B[38;5;241m.\u001B[39mgt_(\u001B[38;5;241m0.0\u001B[39m)\n",
      "File \u001B[1;32mE:\\ultralytics-main\\ultralytics\\utils\\loss.py:202\u001B[0m, in \u001B[0;36mv8DetectionLoss.preprocess\u001B[1;34m(self, targets, batch_size, scale_tensor)\u001B[0m\n\u001B[0;32m    200\u001B[0m         n \u001B[38;5;241m=\u001B[39m matches\u001B[38;5;241m.\u001B[39msum()\n\u001B[0;32m    201\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n:\n\u001B[1;32m--> 202\u001B[0m             \u001B[43mout\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43mn\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m targets[matches, \u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m    203\u001B[0m     out[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;241m1\u001B[39m:\u001B[38;5;241m5\u001B[39m] \u001B[38;5;241m=\u001B[39m xywh2xyxy(out[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;241m1\u001B[39m:\u001B[38;5;241m5\u001B[39m]\u001B[38;5;241m.\u001B[39mmul_(scale_tensor))\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "from ultralytics import RTDETR\n",
    "\n",
    "#增加epochs参数，训练次数增加到100,就涨了好多\n",
    "# Load a model\n",
    "# model = YOLO(r\"./data/BonesOfHand_keypoint/YOLODataset/yolov8n_FasterNet.yaml\")\\\n",
    "#     .load(r\"./yolov8n.pt\")\n",
    "# model = YOLO(r\"./data/BonesOfHand_keypoint/YOLODataset/LeYOLO-nano.yaml\")\n",
    "# model = YOLO(r\"C:/Users/Administrator/Desktop/Chinese/yolov8n.pt\")\n",
    "model = YOLO(r\"yolov8n.pt\")\n",
    "model = YOLO(r\"E:/ultralytics-main/ultralytics/cfg/models/v8/yolov8.yaml\")\n",
    "# model = RTDETR('rtdetr-l.pt')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=r'./data/BonesOfHand_keypoint/YOLODataset/dataset.yaml',\n",
    "                cache=False,\n",
    "                imgsz=640,\n",
    "                epochs=200,\n",
    "                batch=8,\n",
    "                close_mosaic=0,\n",
    "                workers=0,\n",
    "                device=0,\n",
    "                optimizer='SGD',\n",
    "                amp=False,\n",
    "                seed=2025,\n",
    "                )\n",
    "# results = model.train(data=r'./data/BonesOfHand_keypoint/YOLODataset/dataset.yaml' ,\n",
    "#                       epochs=500,imgsz=640, batch=16,verbose=False,pose=25, seed=2024)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T14:33:34.764156200Z",
     "start_time": "2025-06-06T14:33:34.710329Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mval()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:44:45.993757400Z",
     "start_time": "2025-06-07T07:44:45.676817700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 29 chineses, 10.9ms\n",
      "Speed: 3.0ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001B[1mruns\\detect\\predict22\u001B[0m\n",
      "1 label saved to runs\\detect\\predict22\\labels\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "#加载训练好的模型\n",
    "# model = YOLO(r\"./newModel_weights/best.pt\")\n",
    "model = YOLO(r\"C:/Users/Administrator/Desktop/Chinese/testImage/LeYOLO-best.pt\")\n",
    "# model = YOLO(r\"./yolov8n.pt\")\n",
    "\n",
    "im2 = cv2.imread(r\"./testImage/qu_241.png\")\n",
    "results = model.predict(source=im2, save=True, save_txt=True,iou=0.5, show_labels=False)  # save predictions as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T14:33:45.322870300Z",
     "start_time": "2025-06-06T14:33:44.361870100Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m im \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./runs/detect/predict6/image0.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m10\u001B[39m,\u001B[38;5;241m10\u001B[39m))\n\u001B[1;32m----> 4\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\y8work\\lib\\site-packages\\matplotlib\\pyplot.py:2695\u001B[0m, in \u001B[0;36mimshow\u001B[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001B[0m\n\u001B[0;32m   2689\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mimshow)\n\u001B[0;32m   2690\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mimshow\u001B[39m(\n\u001B[0;32m   2691\u001B[0m         X, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, aspect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, interpolation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   2692\u001B[0m         alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, vmin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, vmax\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, origin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, extent\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   2693\u001B[0m         interpolation_stage\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, filternorm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, filterrad\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4.0\u001B[39m,\n\u001B[0;32m   2694\u001B[0m         resample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, url\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m-> 2695\u001B[0m     __ret \u001B[38;5;241m=\u001B[39m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2696\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcmap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcmap\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnorm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maspect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maspect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2697\u001B[0m \u001B[43m        \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2698\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvmax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmax\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morigin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morigin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2699\u001B[0m \u001B[43m        \u001B[49m\u001B[43minterpolation_stage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation_stage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2700\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilternorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilternorm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilterrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilterrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2701\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2702\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2703\u001B[0m     sci(__ret)\n\u001B[0;32m   2704\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m __ret\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\y8work\\lib\\site-packages\\matplotlib\\__init__.py:1474\u001B[0m, in \u001B[0;36m_preprocess_data.<locals>.inner\u001B[1;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1471\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m   1472\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(ax, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1473\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1474\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43max\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1476\u001B[0m     bound \u001B[38;5;241m=\u001B[39m new_sig\u001B[38;5;241m.\u001B[39mbind(ax, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1477\u001B[0m     auto_label \u001B[38;5;241m=\u001B[39m (bound\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mget(label_namer)\n\u001B[0;32m   1478\u001B[0m                   \u001B[38;5;129;01mor\u001B[39;00m bound\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(label_namer))\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\y8work\\lib\\site-packages\\matplotlib\\axes\\_axes.py:5663\u001B[0m, in \u001B[0;36mAxes.imshow\u001B[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001B[0m\n\u001B[0;32m   5655\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_aspect(aspect)\n\u001B[0;32m   5656\u001B[0m im \u001B[38;5;241m=\u001B[39m mimage\u001B[38;5;241m.\u001B[39mAxesImage(\u001B[38;5;28mself\u001B[39m, cmap\u001B[38;5;241m=\u001B[39mcmap, norm\u001B[38;5;241m=\u001B[39mnorm,\n\u001B[0;32m   5657\u001B[0m                       interpolation\u001B[38;5;241m=\u001B[39minterpolation, origin\u001B[38;5;241m=\u001B[39morigin,\n\u001B[0;32m   5658\u001B[0m                       extent\u001B[38;5;241m=\u001B[39mextent, filternorm\u001B[38;5;241m=\u001B[39mfilternorm,\n\u001B[0;32m   5659\u001B[0m                       filterrad\u001B[38;5;241m=\u001B[39mfilterrad, resample\u001B[38;5;241m=\u001B[39mresample,\n\u001B[0;32m   5660\u001B[0m                       interpolation_stage\u001B[38;5;241m=\u001B[39minterpolation_stage,\n\u001B[0;32m   5661\u001B[0m                       \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 5663\u001B[0m \u001B[43mim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5664\u001B[0m im\u001B[38;5;241m.\u001B[39mset_alpha(alpha)\n\u001B[0;32m   5665\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m im\u001B[38;5;241m.\u001B[39mget_clip_path() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   5666\u001B[0m     \u001B[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\y8work\\lib\\site-packages\\matplotlib\\image.py:701\u001B[0m, in \u001B[0;36m_ImageBase.set_data\u001B[1;34m(self, A)\u001B[0m\n\u001B[0;32m    697\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A \u001B[38;5;241m=\u001B[39m cbook\u001B[38;5;241m.\u001B[39msafe_masked_invalid(A, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    699\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39muint8 \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m    700\u001B[0m         \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39mcan_cast(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mdtype, \u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msame_kind\u001B[39m\u001B[38;5;124m\"\u001B[39m)):\n\u001B[1;32m--> 701\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage data of dtype \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m cannot be converted to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    702\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfloat\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mdtype))\n\u001B[0;32m    704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;66;03m# If just one dimension assume scalar and apply colormap\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A[:, :, \u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mTypeError\u001B[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "im = cv2.imread('./runs/detect/predict6/image0.jpg')\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T14:33:58.214168200Z",
     "start_time": "2025-06-06T14:33:58.190240700Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mresults\u001B[49m[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mkeypoints\u001B[38;5;241m.\u001B[39mxy )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "print(results[0].keypoints.xy )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8_troch2_0_cuda_11_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
